<!DOCTYPE html>
<html>

<!-- Services Section -->
    <section id="projects">
        <div class="container">

			<div class="row">
				<h1 class="section-heading text-center">BHD2025  Projects</h1>
					
			<p class="text-muted"> Take a look at BHD2025's projects! </p>
					<hr>
					
			<!-- division for project-->
			<h3 class="section-heading text-center">A Brainphack Project: Assessing false discovery rates in cog neuro <br/> <a href="https://github.com/qtabs/abrainphackproject"> (Alejandro Tabas)</a> </h3>

			<p class="text-muted"> P-hacking is the practice of selectively reporting or analysing data until statistical significance is achieved, often inflating false positives. 
				Despite its prevalence, quantifying how difficult specific results are to obtain via p-hacking is a cumbersome task. This project introduces a novel metric, the 
				estimated P-Hacking Attempt-Insistence-Length (phail), defined as the expected number of times researchers would need to rerun their analyses to obtain the number 
				of significant results reported in a paper. We will apply this measure to a sample of highly cited behavioural and cognitive neuroscience studies. The project will 
				produce a library that computes the phail, providing an accessible resource for researchers and meta-scientists. If time allows, we will begin automating the full 
				workflow from paper to index computation. Ultimately, this project aims to deliver a practical tool for assessing the reliability of specific methodological pipelines 
				and tools, and support the assessment of authors, reviewers, and editors.</p>
			<h3 class="section-subsubheading text-muted">
				Goals</h3>
			<p class="text-muted"> 1. Define and formalise the P-Hacking Attempt-Insistence-Length (phail)<br />
			2. Think of a better name/acronym (BNA) for the phail<br />
			3. Select a set of behavioural-experiment papers in cognitive neuroscience for testing<br /> 
			4. Code the analysis pipelines of the selected papers and use simulations to estimate BNA<br /> 
			5. Create visualisations summarising the BNA distribution across studies (hopefully N > 20)<br /> 
			6. Scale up the code to an open-source library for the general computation of BNA<br />
			7. Devise a very cool name and acronym for the library<br /> 
			8. Explore automation of the end-to-end paper → BNA computation pipeline<br /> 
			9. Draft a short report detailing motivation, methods, findings, and next steps<br /> </p>
			<hr>


			<h3 class="section-heading text-center">Implementing denoising within phys2cvr software <br/> <a href="https://github.com/Brainhack-Donostia/brainhack-donostia.github.io/issues/172"> (César Caballero Gaudes)</a> </h3>

			<p class="text-muted"> This project will aim to implement a denoising module within the phys2cvr software for cerebrovascular reactivity mapping. Briefly, we will create a module that 
				implements the removal of the nuisance regressors (i.e. denoising) based on the lagged-GLM approach of phys2cvr. 
				This will involve understanding the phys2cvr pipeline and developing an efficient approach of the denoising step. </p>
			<h3 class="section-subsubheading text-muted">
				Goals</h3>

			<p class="text-muted"> The deliverable will be to implement this step and make it work.<br /> </p>
			<hr>



			<h3 class="section-heading text-center">FAIR-PsyFlow: making psychological assessment methods and data FAIR by design <br/> <a href="https://github.com/Brainhack-Donostia/brainhack-donostia.github.io/issues/173"> (Inês Almeida)</a> </h3>

			<p class="text-muted"> This workshop aims to discuss barriers, opportunities and best practices in psychological assessment (with extensions, input from and output to 
				behavioural research) using the lens of responsible and open science, reproducibility and FAIR principles. The end goal is to provide an opportunity for critically 
				thinking about these topics, hands-on training, and to create a workflow to guide researchers in best practices from the project starting point.</p>
			<h3 class="section-subsubheading text-muted">
				Goals</h3>
			<p class="text-muted"> The workshop aims to build insight and develop a best-practices workflow (in line with responsible and open research, and FAIR principles) 
				for psychology that can be used, collaboratively worked and reused by others - with particular focus in the field of psychological assessment methods and data. 
				The goal it to make methods selection, application & reporting, and data management & sharing more transparent, easy and best practices compliant, motivating 
				all to prepare responsibly and share transparently their research practices and outputs – which are more diverse than a final thesis, research article or publication!<br />

				By the end of the workshop, a workflow (draft version) to implement in GitHub or in another collaborative platform should be created. This should contain key steps, 
				best practices and useful resources to think critically when designing a study or project in Psychology research (in particular when using psychological assessment methods and data).<br /> </p>
			<hr>




			<h3 class="section-heading text-center">"I know that I know nothing", or do I? A workshop on priors for Bayesian Modeling <br/> <a href="https://gitlab.com/urrestarazu/brainhack-priors"> (Iñigo Urrestarazu-Porta)</a> </h3>

			<p class="text-muted"> Bayesian Data Analysis (BDA) offers a powerful toolkit to study human
				cognition and, overall, behaviour, where data collection tends to be
				very demanding, limited, and time consuming. Yet, BDA often becomes a
				daunting experience as it requires that the analyst specifies prior
				distributions for all model parameters, and newcomers to BDA often feel
				that they do not know at all how to define sensible priors for their
				analysis. In consequence, they rely on the default priors used by the
				software implementation used, e.g. brms (Bürkner 2017). <br/>
				In the workshop, we will work on how to define (sensible) priors for a
				range of data sets. First, we shall see that, upon reflection, reasoning
				and the most simple knowledge of the world allows to constrain the
				parameter space of priors. Second, researchers are experts in their own
				fields, and we will discuss how we can leverage our expertise to find
				(more) suitable priors. Finally, we will approach prior definition
				through data simulation, as an empirical workflow to reassure our choice
				of prior distributions. Thus, the workshop aims to empower analysts to
				take full advantage of the possibilities offered by BDA.<br/></p>
			<h3 class="section-subsubheading text-muted">
				Goals</h3>
			<p class="text-muted"> The goal is pretty simple: learn how to think about priors, and apply that knowledge to your own research.<br/> </p>
			<hr>





			<h3 class="section-heading text-center">Developing a tool to estimate and report the carbon footprint of neuroimaging research <br/> <a href="https://github.com/Brainhack-Donostia/brainhack-donostia.github.io/issues/174"> (Nick Souter)</a> </h3>

			<p class="text-muted"> This project will focus on workshopping, building, and disseminating a single tool which will allow neuroimaging researchers to estimate the 
				environmental impact of their research, based on factors including imaging modality, duration of data collection, and analysis software choice. Such a tool could 
				be used prospectively during grant writing, or retrospectively during manuscript writing.</p>
			<h3 class="section-subsubheading text-muted">
				Goals</h3>
			<p class="text-muted"> 1. Establish the scope of this tool including imaging modality (MRI only, or more diverse?), and aspect of the research process to be estimated 
				(e.g., data collection, analysis, and dissemination)<br />
				2. Collate appropriate benchmark statistics relating to the carbon footprint of various aspects of the research process <br />
				3. Establish and the most appropriate format for this tool (e.g., Python package, dedicated webpage)<br />
				4. Start work on a digital tool to allow neuroimaging researchers to estimate the environmental impact of their work<br />
				5. Produce clear documentation to facilitate easy tool use and explain methodology<br />
				6. Produce branding for the tool, including a clear and effective name and appealing visuals<br /></p>

			<hr>




			<h3 class="section-heading text-center">Open Data BIDSifier: LLM-based BIDSifier and metadata harmonization for non-BIDS datasets <br/> <a href="https://github.com/stefanches7/AI-assisted-Neuroimaging-harmonization"> (Stefan Dvoretskii)</a> </h3>

			<p class="text-muted"> The goal of this project is to explore if LLM-based workflow machines (sometimes calles "AI agents) can meaningfully assist in metadata 
				harmonization, data format transformation and data preprocessing tasks that precede AI model inference or training. These tasks are time-consuming yet essential 
				to reproducible, large-scale neuroimaging research.<br />
				While the BIDS standard ensures interoperability, there are some datasets for which no BIDS annotation is available. This is a "dead data" which can not 
				be used on-par with BIDS datasets.<br />
				In this proof-of-concept, we aim to determine whether a coordinated system of AI agents can reliably execute these operations and produce AI-ready dataset 
				collections, similar to those hosted on platforms like HuggingFace Datasets: OpenMind, with minimal human intervention.<br /></p>
			<h3 class="section-subsubheading text-muted">
				Goals</h3>
			<p class="text-muted"> If successful, Open Data BIDSifier will serve as a foundation for an AI agent that can identify and harmonize different datasets 
				from open data, making sure these are immediately usable for machine learning and statistical analysis. <br/>
				If successful, the developed data harmonizer tool will be published as a Python executable, as well as a HuggingFace space.<br/></p>

			<hr>







			<h3 class="section-heading text-center">Fast Voxel-wise fMRI Correlation Mapping Using Phase Derivatives in LayNii IDA <br/> <a href="https://github.com/Brainhack-Donostia/brainhack-donostia.github.io/issues/180"> (Omer Faruk Gulban)</a> </h3>

			<p class="text-muted"> Functional MRI analysis increasingly demands both higher spatial and higher temporal resolution: mesoscopic fMRI (submillimeter) reveals 
				cortical microstructure and layer-dependent signals, while ultrafast sampling (tens of Hz) captures rapid hemodynamic and physiological dynamics. Extracting 
				meaningful functional relationships at these scales requires voxel-wise correlation and connectivity computations across very large spatiotemporal arrays, 
				an operation that is computationally intensive and often prohibitive with standard toolboxes.<br/>
				Here we introduce LayNii IDA, a purpose-built, highly optimized implementation for voxel-wise correlation and related voxel-wise operations that (i) scales 
				to submillimeter whole-brain or slab fMRI volumes, (ii) handles ultrafast single-slice and multi-slice acquisitions sampled at tens of Hz, and (iii) integrates 
				preprocessing and on-the-fly statistical transforms to minimize I/O and memory overhead. We demonstrate that LayNii IDA enables exploratory, data-driven 
				investigation of mesoscopic functional structure (layer- and column-scale), vascular structure, dynamic functional connectivity, and rapid quality control 
				workflows that previously required ROI strategies. For this Brainhack, we specifically aim to extend IDA with phase-based fMRI time-series analysis using 
				spatial phase derivatives. This implementation will allow voxel-wise correlation analyses in the phase domain, offering an alternative to the conventional 
				magnitude domain fMRI time series.<br/></p>
			<h3 class="section-subsubheading text-muted">
				Goals</h3>
			<p class="text-muted"> 1. Load and interact with phase fMRI time series data<br />
				2. Implement circular grayscale and/or variants to visualize phase timeseries within the GUI <br />
				3. Implement phase spatial derivatives (first and second order)<br />
				4. Explore various phase fMRI datasets using voxel-wise correlations<br />
				5. Report interesting findings.<br /></p>

			<hr>


			<div class="row">
			
		    
       </div>
</html>
